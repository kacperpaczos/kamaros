# ğŸŒŠ Streaming Architecture - ObsÅ‚uga DuÅ¼ych PlikÃ³w

Architektura Kamaros zostaÅ‚a zaprojektowana z zaÅ‚oÅ¼eniem "Stream First", co pozwala na obsÅ‚ugÄ™ plikÃ³w o dowolnym rozmiarze (nawet > GB) przy minimalnym zuÅ¼yciu pamiÄ™ci RAM.

## 1. Problem: Memory Overflow

W standardowym podejÅ›ciu (caÅ‚y plik w pamiÄ™ci):
- Plik 500MB â†’ Alokacja 500MB ArrayBuffer
- Crash w przeglÄ…darce (limit pamiÄ™ci tab/worker)
- Blokada UI podczas alokacji/kopiowania

W podejÅ›ciu Kamaros:
- Plik 500MB â†’ Bufor 64KB (chunk)
- StaÅ‚e zuÅ¼ycie pamiÄ™ci niezaleÅ¼nie od rozmiaru pliku
- Brak blokady UI

## 2. Architektura PrzepÅ‚ywu Danych

Kamaros wykorzystuje standard **WHATWG Streams API** (`ReadableStream`, `WritableStream`, `TransformStream`) dostÄ™pny w przeglÄ…darkach, Node.js i Deno.

### 2.1 Pipeline: Upload (Save)

```mermaid
graph LR
    Input[File Input] -->|ReadableStream| Splitter[Tee Splitter]
    
    Splitter -->|Branch A| Hasher[Hash Transform]
    Splitter -->|Branch B| Compressor[Deflate Transform]
    
    Hasher -->|Progress hash| Verify[Integrity Check]
    Compressor -->|Compressed Chunks| Writer[ZIP Writer]
    
    Writer -->|Final ZIP| Storage[FileSystem]
```

### 2.2 Pipeline: Download (Restore)

```mermaid
graph LR
    Storage[FileSystem] -->|ReadableStream| Reader[ZIP Reader]
    
    Reader -->|Compressed Chunks| Decompressor[Inflate Transform]
    Decompressor -->|Raw Chunks| Writer[File System Writer]
    
    Writer -->|Write to Disk| Disk[User Disk]
```

## 3. Implementacja Techniczna

### 3.1 Interfejs Streams

```typescript
interface FileSystemAdapter {
  // Zamiast Promise<Uint8Array>, zwracamy strumieÅ„
  readFileStream(path: string): Promise<ReadableStream<Uint8Array>>;
  
  // Zapis strumieniowy z backpressure
  writeFileStream(path: string, stream: ReadableStream<Uint8Array>): Promise<void>;
}
```

### 3.2 Hashing Stream (SHA-256)

Obliczanie hasha "w locie" bez Å‚adowania caÅ‚oÅ›ci:

```typescript
async function computeHashFromStream(stream: ReadableStream): Promise<string> {
  const reader = stream.getReader();
  const hasher = crypto.createHash('sha256'); // Node.js lub WebCrypto wrapper
  
  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      // Update hash state with chunk
      hasher.update(value);
      
      // Bonus: Report progress
      reportProgress(value.length);
    }
  } finally {
    reader.releaseLock();
  }
  
  return hasher.digest('hex');
}
```

### 3.3 Streaming ZIP (fflate modification)

UÅ¼ywamy zmodyfikowanej wersji `fflate`, ktÃ³ra wspiera kompresjÄ™ strumieniowÄ…:

```typescript
import { ZipDeflate, AsyncZipDeflate } from 'fflate';

function createZipStream(files: StreamFile[]): ReadableStream {
  // Create ZIP structure on the fly
  const zip = new AsyncZipDeflate(files[0].name, { level: 6 });
  
  files[0].stream.pipeTo(new WritableStream({
    write(chunk) {
      zip.push(chunk, false); // false = not final
    },
    close() {
      zip.push(new Uint8Array(0), true); // true = final
    }
  }));
  
  return zip.stream; // Output stream of ZIP bytes
}
```

## 4. Backpressure i Chunking

### 4.1 Co to jest Backpressure?
JeÅ›li dysk jest wolniejszy niÅ¼ sieÄ‡ (lub odwrotnie), bufor moÅ¼e siÄ™ przepeÅ‚niÄ‡. Streams API automatycznie obsÅ‚uguje **backpressure**:
- JeÅ›li `WritableStream` jest zajÄ™ty, sygnaÅ‚ jest wysyÅ‚any do `ReadableStream`.
- `ReadableStream` przestaje czytaÄ‡ ÅºrÃ³dÅ‚o (pauzuje).
- PamiÄ™Ä‡ RAM jest bezpieczna.

### 4.2 Rozmiar Chunka (Chunk Size)
DomyÅ›lny rozmiar chunka w Kamaros: **64KB**.
- Kompromis miÄ™dzy wydajnoÅ›ciÄ… (mniej wywoÅ‚aÅ„ funkcji) a pamiÄ™ciÄ….
- Konfigurowalne w `JCFConfig`.

## 5. Web Workers Integration

Dla maksymalnej wydajnoÅ›ci, strumienie mogÄ… byÄ‡ transferowane do WorkerÃ³w (`Transferable objects`).

```typescript
// Main Thread
const fileStream = file.stream();
worker.postMessage({ stream: fileStream }, [fileStream]);

// Worker Thread
self.onmessage = (e) => {
  const stream = e.data.stream;
  // Process stream in worker (hash, compress)
  // Nie blokuje UI w gÅ‚Ã³wnym wÄ…tku!
};
```

## 6. Edge Cases

### 6.1 BÅ‚Ä™dy w trakcie streamu
JeÅ›li stream zostanie przerwany (np. bÅ‚Ä…d sieci):
1. `reader.read()` rzuca wyjÄ…tek.
2. Pipeline jest przerywany (`abort()`).
3. Tymczasowe pliki (partial uploads) sÄ… usuwane (`.store/temp/`).

### 6.2 Anulowanie (Cancellation)
UÅ¼ytkownik moÅ¼e anulowaÄ‡ dÅ‚ugi upload:
```typescript
const controller = new AbortController();
await manager.addFile(path, stream, { signal: controller.signal });

// Later...
controller.abort(); // Przerywa strumieÅ„ natychmiast
```

---
**Zobacz teÅ¼**:
- [Content Addressable Storage](./04-content-addressing.md) - jak streamujemy do CAS.
- [Workers](./06-workers.md) - offloading obliczeÅ„.